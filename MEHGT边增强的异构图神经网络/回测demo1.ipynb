{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import HeteroData\n",
    "from hgt_conv_edge_attr import HGTConv\n",
    "from torch_geometric.nn import HANConv,SAGEConv,to_hetero, Linear\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score\n",
    "import torch_geometric.transforms as T\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"自定义的异构图数据集类\"\"\"\n",
    "    def __init__(self, root, transform=None, pre_transform=None, indices=None):\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.file_list = [f for f in os.listdir(root) if f.endswith('.pt')]\n",
    "        \n",
    "        if indices is not None:\n",
    "            # 如果提供了索引，根据索引筛选文件\n",
    "            self.file_list = [self.file_list[i] for i in indices]\n",
    "\n",
    "    def len(self):\n",
    "        \"\"\"返回数据集中的图数量\"\"\"\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        \"\"\"加载并返回指定索引处的图\"\"\"\n",
    "        file_path = os.path.join(self.root, self.file_list[idx])\n",
    "        data = torch.load(file_path)\n",
    "        return data\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\"返回处理后的文件名列表\"\"\"\n",
    "        return self.filenames\n",
    "\n",
    "\n",
    "# 数据集文件夹路径\n",
    "root_path = '/home/QFRC/ZQS/Projects/Graph/Scripts_demo/Graphs_demos/Graphs3days_all1.0'\n",
    "\n",
    "# 创建数据集实例\n",
    "dataset = CustomDataset(root=root_path)\n",
    "batch_size= 512\n",
    "# 数据集的长度\n",
    "dataset_length = len(dataset)\n",
    "\n",
    "# 计算各个子集的索引范围\n",
    "train_size = int(0.7 * dataset_length)\n",
    "val_size = int(0.2 * dataset_length)\n",
    "test_size = dataset_length - train_size - val_size  # 剩下的部分为测试集\n",
    "\n",
    "# 生成顺序索引\n",
    "indices = list(range(dataset_length))\n",
    "\n",
    "# 根据比例按顺序切分数据集\n",
    "train_indices = indices[:train_size]  # 前70%的索引\n",
    "val_indices = indices[train_size:train_size + val_size]  # 接下来的20%\n",
    "test_indices = indices[train_size + val_size:]  # 最后的10%\n",
    "\n",
    "# 根据索引创建数据集的子集\n",
    "train_dataset = CustomDataset(root=root_path, indices=train_indices)\n",
    "val_dataset = CustomDataset(root=root_path, indices=val_indices)\n",
    "test_dataset = CustomDataset(root=root_path, indices=test_indices)\n",
    "\n",
    "# 创建对应的DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697]\n",
      "38.05\n",
      "41.5\n",
      "[544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698]\n",
      "tensor([[2.9950e+01, 3.0750e+01, 2.9070e+01, 3.0170e+01, 1.0434e+08, 2.9800e+01,\n",
      "         3.0580e+01, 2.9680e+01, 3.0400e+01, 5.4960e+07, 3.0230e+01, 3.1750e+01,\n",
      "         2.9980e+01, 3.0800e+01, 6.1509e+07],\n",
      "        [3.6000e+01, 3.6620e+01, 3.5300e+01, 3.5600e+01, 3.9528e+07, 3.5600e+01,\n",
      "         3.5870e+01, 3.4800e+01, 3.5800e+01, 2.7120e+07, 3.5500e+01, 3.6720e+01,\n",
      "         3.4600e+01, 3.6460e+01, 5.1847e+07],\n",
      "        [4.3250e+01, 4.4510e+01, 4.2270e+01, 4.2880e+01, 6.1472e+07, 4.2380e+01,\n",
      "         4.4480e+01, 4.1700e+01, 4.4320e+01, 6.4272e+07, 4.4890e+01, 4.7880e+01,\n",
      "         4.4890e+01, 4.6400e+01, 9.6965e+07],\n",
      "        [2.1000e+01, 2.2110e+01, 2.0700e+01, 2.1920e+01, 6.3788e+07, 2.1790e+01,\n",
      "         2.1800e+01, 2.1210e+01, 2.1450e+01, 3.5933e+07, 2.1580e+01, 2.2740e+01,\n",
      "         2.1060e+01, 2.1680e+01, 5.2527e+07],\n",
      "        [5.4990e+01, 5.7160e+01, 5.4200e+01, 5.7000e+01, 1.2957e+07, 5.6500e+01,\n",
      "         5.7250e+01, 5.5350e+01, 5.6500e+01, 8.6335e+06, 5.6220e+01, 5.7800e+01,\n",
      "         5.5550e+01, 5.6200e+01, 8.9068e+06],\n",
      "        [7.4000e+01, 7.7500e+01, 7.2000e+01, 7.3520e+01, 1.0696e+07, 7.2730e+01,\n",
      "         7.5200e+01, 7.2080e+01, 7.3000e+01, 7.4850e+06, 7.3100e+01, 7.3550e+01,\n",
      "         7.0120e+01, 7.0830e+01, 7.9389e+06],\n",
      "        [4.0988e+02, 4.0988e+02, 3.8600e+02, 3.9000e+02, 2.3005e+07, 3.8550e+02,\n",
      "         4.0440e+02, 3.8000e+02, 4.0117e+02, 1.6560e+07, 4.0000e+02, 4.1050e+02,\n",
      "         3.7298e+02, 3.8500e+02, 2.7262e+07],\n",
      "        [2.3459e+02, 2.4500e+02, 2.3098e+02, 2.3486e+02, 5.3425e+07, 2.3180e+02,\n",
      "         2.3975e+02, 2.2000e+02, 2.3699e+02, 4.3312e+07, 2.3800e+02, 2.4988e+02,\n",
      "         2.2969e+02, 2.3930e+02, 4.8035e+07],\n",
      "        [1.1080e+02, 1.1080e+02, 1.0477e+02, 1.0615e+02, 9.8529e+07, 1.0566e+02,\n",
      "         1.1062e+02, 1.0488e+02, 1.0995e+02, 8.5406e+07, 1.1012e+02, 1.1437e+02,\n",
      "         1.0665e+02, 1.0818e+02, 8.7998e+07],\n",
      "        [9.6890e+01, 9.6990e+01, 8.8050e+01, 8.9750e+01, 4.7130e+07, 8.9110e+01,\n",
      "         9.4400e+01, 8.9100e+01, 9.3330e+01, 2.6713e+07, 9.4010e+01, 9.6800e+01,\n",
      "         8.8080e+01, 8.9940e+01, 3.4164e+07],\n",
      "        [4.2110e+01, 4.2110e+01, 3.8530e+01, 3.9320e+01, 1.5416e+08, 3.9400e+01,\n",
      "         4.0830e+01, 3.8800e+01, 4.0410e+01, 1.0502e+08, 4.0400e+01, 4.1560e+01,\n",
      "         3.8820e+01, 3.9350e+01, 1.0964e+08],\n",
      "        [8.4500e+01, 8.4500e+01, 7.7800e+01, 8.1020e+01, 5.2810e+07, 8.1000e+01,\n",
      "         8.9000e+01, 7.9770e+01, 8.6910e+01, 5.3012e+07, 8.6500e+01, 9.2800e+01,\n",
      "         8.5970e+01, 8.8200e+01, 4.9831e+07]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor(29.9500)\n",
      "<class 'torch.Tensor'>\n",
      "29.95\n",
      "30.23\n"
     ]
    }
   ],
   "source": [
    "# 3days\n",
    "\n",
    "print(val_indices)\n",
    "label_indices_pre=[x + 1 for x in val_indices]\n",
    "open_price=round(dataset[542]['stock'].x[0,10].item(), 2)\n",
    "close_price=round(dataset[542]['stock'].x[0,13].item(), 2)\n",
    "print(open_price)\n",
    "print(close_price)\n",
    "\n",
    "print(label_indices_pre)\n",
    "\n",
    "print(dataset[0]['stock'].x)\n",
    "print(type(dataset[0]['stock'].x))\n",
    "print(dataset[0]['stock'].x[0,0])\n",
    "print(type(dataset[0]['stock'].x[0,0]))\n",
    "\n",
    "float_value=round(dataset[0]['stock'].x[0,0].item(), 2)\n",
    "print(float_value)\n",
    "print(round(dataset[0]['stock'].x[0,10].item(), 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5days\n",
    "\n",
    "print(val_indices)\n",
    "label_indices_pre=[x + 1 for x in val_indices]\n",
    "open_price=round(dataset[542]['stock'].x[0,20].item(), 2)\n",
    "close_price=round(dataset[542]['stock'].x[0,23].item(), 2)\n",
    "print(open_price)\n",
    "print(close_price)\n",
    "\n",
    "print(label_indices_pre)\n",
    "\n",
    "print(dataset[0]['stock'].x)\n",
    "print(type(dataset[0]['stock'].x))\n",
    "print(dataset[0]['stock'].x[0,0])\n",
    "print(type(dataset[0]['stock'].x[0,0]))\n",
    "\n",
    "float_value=round(dataset[0]['stock'].x[0,0].item(), 2)\n",
    "print(float_value)\n",
    "print(round(dataset[0]['stock'].x[0,20].item(), 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38.05, 42.0, 43.0, 39.39, 38.51, 39.7, 41.3, 42.1, 41.9, 43.0, 46.0, 46.2, 43.5, 38.52, 40.6, 41.5, 38.78, 38.01, 39.0, 36.3, 35.34, 35.78, 35.9, 35.6, 37.36, 39.95, 39.08, 38.5, 36.92, 39.8, 40.45, 41.0, 39.45, 44.5, 43.55, 45.28, 44.08, 44.75, 43.47, 42.62, 42.67, 45.41, 45.0, 48.99, 52.2, 51.7, 58.21, 62.15, 62.6, 59.61, 57.0, 50.73, 47.07, 46.97, 48.0, 47.61, 47.37, 45.9, 47.78, 46.05, 45.0, 42.58, 41.2, 42.75, 44.25, 47.56, 47.0, 44.89, 43.05, 42.4, 46.01, 46.68, 44.4, 45.0, 46.58, 45.08, 47.07, 46.18, 47.2, 51.7, 49.91, 48.72, 46.3, 47.56, 44.88, 47.47, 43.49, 42.15, 42.67, 40.86, 41.62, 42.03, 42.0, 40.3, 39.28, 36.92, 39.1, 38.9, 39.0, 38.85, 38.86, 37.65, 37.37, 36.22, 35.38, 37.5, 37.9, 37.7, 37.66, 35.54, 35.5, 35.28, 34.48, 36.4, 37.39, 36.56, 36.7, 36.65, 37.0, 37.6, 36.85, 37.94, 36.5, 35.24, 35.0, 32.32, 30.0, 30.8, 29.31, 28.6, 28.5, 27.98, 29.03, 29.0, 29.75, 30.18, 30.1, 29.11, 30.3, 30.88, 31.5, 31.73, 34.1, 34.44, 34.75, 35.35, 34.2, 34.22, 35.25, 37.69, 36.28, 35.77, 37.59, 35.98, 35.31]\n",
      "[38.05, 38.05, 42.0, 43.0, 39.39, 38.51, 39.7, 41.3, 42.1, 41.9, 43.0, 46.0, 46.2, 43.5, 38.52, 40.6, 41.5, 38.78, 38.01, 39.0, 36.3, 35.34, 35.78, 35.9, 35.6, 37.36, 39.95, 39.08, 38.5, 36.92, 39.8, 40.45, 41.0, 39.45, 44.5, 43.55, 45.28, 44.08, 44.75, 43.47, 42.62, 42.67, 45.41, 45.0, 48.99, 52.2, 51.7, 58.21, 62.15, 62.6, 59.61, 57.0, 50.73, 47.07, 46.97, 48.0, 47.61, 47.37, 45.9, 47.78, 46.05, 45.0, 42.58, 41.2, 42.75, 44.25, 47.56, 47.0, 44.89, 43.05, 42.4, 46.01, 46.68, 44.4, 45.0, 46.58, 45.08, 47.07, 46.18, 47.2, 51.7, 49.91, 48.72, 46.3, 47.56, 44.88, 47.47, 43.49, 42.15, 42.67, 40.86, 41.62, 42.03, 42.0, 40.3, 39.28, 36.92, 39.1, 38.9, 39.0, 38.85, 38.86, 37.65, 37.37, 36.22, 35.38, 37.5, 37.9, 37.7, 37.66, 35.54, 35.5, 35.28, 34.48, 36.4, 37.39, 36.56, 36.7, 36.65, 37.0, 37.6, 36.85, 37.94, 36.5, 35.24, 35.0, 32.32, 30.0, 30.8, 29.31, 28.6, 28.5, 27.98, 29.03, 29.0, 29.75, 30.18, 30.1, 29.11, 30.3, 30.88, 31.5, 31.73, 34.1, 34.44, 34.75, 35.35, 34.2, 34.22, 35.25, 37.69, 36.28, 35.77, 37.59, 35.98, 35.31]\n",
      "[41.5, 41.5, 43.87, 39.54, 38.9, 39.96, 41.78, 41.3, 42.98, 43.96, 47.0, 47.1, 43.94, 42.38, 41.1, 41.88, 38.86, 38.22, 38.66, 36.08, 35.34, 35.51, 35.91, 35.36, 38.34, 38.89, 39.09, 39.5, 37.4, 37.15, 39.92, 41.38, 39.8, 43.78, 44.56, 45.29, 44.4, 44.65, 43.79, 42.62, 43.05, 45.67, 45.23, 49.12, 52.5, 52.02, 56.5, 62.15, 65.0, 61.48, 56.71, 56.52, 50.73, 48.04, 48.5, 47.36, 47.36, 46.53, 48.01, 46.02, 45.27, 45.78, 41.2, 42.2, 43.87, 46.04, 46.98, 45.11, 43.25, 42.42, 45.86, 46.83, 44.88, 45.12, 47.12, 45.71, 47.7, 47.31, 47.86, 50.6, 50.41, 48.71, 47.05, 47.49, 45.19, 45.82, 44.03, 42.4, 42.79, 40.91, 40.6, 43.0, 40.69, 41.6, 37.44, 36.91, 38.68, 39.54, 39.13, 38.6, 38.98, 37.91, 37.49, 36.36, 35.17, 37.99, 38.2, 37.9, 37.74, 35.82, 35.62, 34.9, 34.93, 36.01, 37.91, 36.57, 37.12, 36.75, 37.61, 37.25, 36.99, 37.9, 36.9, 35.24, 34.84, 34.3, 30.87, 30.9, 29.65, 28.29, 28.45, 28.47, 29.32, 29.22, 29.74, 29.39, 29.71, 29.07, 30.17, 30.89, 31.56, 31.82, 35.0, 34.14, 34.76, 34.86, 34.55, 34.31, 35.7, 37.82, 36.43, 36.42, 37.85, 36.52, 35.09, 35.37]\n",
      "[38.05, 38.05, 42.0, 43.0, 39.39, 38.51, 39.7, 41.3, 42.1, 41.9, 43.0, 46.0, 46.2, 43.5, 38.52, 40.6, 41.5, 38.78, 38.01, 39.0, 36.3, 35.34, 35.78, 35.9, 35.6, 37.36, 39.95, 39.08, 38.5, 36.92, 39.8, 40.45, 41.0, 39.45, 44.5, 43.55, 45.28, 44.08, 44.75, 43.47, 42.62, 42.67, 45.41, 45.0, 48.99, 52.2, 51.7, 58.21, 62.15, 62.6, 59.61, 57.0, 50.73, 47.07, 46.97, 48.0, 47.61, 47.37, 45.9, 47.78, 46.05, 45.0, 42.58, 41.2, 42.75, 44.25, 47.56, 47.0, 44.89, 43.05, 42.4, 46.01, 46.68, 44.4, 45.0, 46.58, 45.08, 47.07, 46.18, 47.2, 51.7, 49.91, 48.72, 46.3, 47.56, 44.88, 47.47, 43.49, 42.15, 42.67, 40.86, 41.62, 42.03, 42.0, 40.3, 39.28, 36.92, 39.1, 38.9, 39.0, 38.85, 38.86, 37.65, 37.37, 36.22, 35.38, 37.5, 37.9, 37.7, 37.66, 35.54, 35.5, 35.28, 34.48, 36.4, 37.39, 36.56, 36.7, 36.65, 37.0, 37.6, 36.85, 37.94, 36.5, 35.24, 35.0, 32.32, 30.0, 30.8, 29.31, 28.6, 28.5, 27.98, 29.03, 29.0, 29.75, 30.18, 30.1, 29.11, 30.3, 30.88, 31.5, 31.73, 34.1, 34.44, 34.75, 35.35, 34.2, 34.22, 35.25, 37.69, 36.28, 35.77, 37.59, 35.98, 35.31]\n",
      "[41.5, 41.5, 43.87, 39.54, 38.9, 39.96, 41.78, 41.3, 42.98, 43.96, 47.0, 47.1, 43.94, 42.38, 41.1, 41.88, 38.86, 38.22, 38.66, 36.08, 35.34, 35.51, 35.91, 35.36, 38.34, 38.89, 39.09, 39.5, 37.4, 37.15, 39.92, 41.38, 39.8, 43.78, 44.56, 45.29, 44.4, 44.65, 43.79, 42.62, 43.05, 45.67, 45.23, 49.12, 52.5, 52.02, 56.5, 62.15, 65.0, 61.48, 56.71, 56.52, 50.73, 48.04, 48.5, 47.36, 47.36, 46.53, 48.01, 46.02, 45.27, 45.78, 41.2, 42.2, 43.87, 46.04, 46.98, 45.11, 43.25, 42.42, 45.86, 46.83, 44.88, 45.12, 47.12, 45.71, 47.7, 47.31, 47.86, 50.6, 50.41, 48.71, 47.05, 47.49, 45.19, 45.82, 44.03, 42.4, 42.79, 40.91, 40.6, 43.0, 40.69, 41.6, 37.44, 36.91, 38.68, 39.54, 39.13, 38.6, 38.98, 37.91, 37.49, 36.36, 35.17, 37.99, 38.2, 37.9, 37.74, 35.82, 35.62, 34.9, 34.93, 36.01, 37.91, 36.57, 37.12, 36.75, 37.61, 37.25, 36.99, 37.9, 36.9, 35.24, 34.84, 34.3, 30.87, 30.9, 29.65, 28.29, 28.45, 28.47, 29.32, 29.22, 29.74, 29.39, 29.71, 29.07, 30.17, 30.89, 31.56, 31.82, 35.0, 34.14, 34.76, 34.86, 34.55, 34.31, 35.7, 37.82, 36.43, 36.42, 37.85, 36.52, 35.09, 35.37]\n",
      "[38.05, 38.05, 42.0, 43.0, 39.39, 38.51, 39.7, 41.3, 42.1, 41.9, 43.0, 46.0, 46.2, 43.5, 38.52, 40.6, 41.5, 38.78, 38.01, 39.0, 36.3, 35.34, 35.78, 35.9, 35.6, 37.36, 39.95, 39.08, 38.5, 36.92, 39.8, 40.45, 41.0, 39.45, 44.5, 43.55, 45.28, 44.08, 44.75, 43.47, 42.62, 42.67, 45.41, 45.0, 48.99, 52.2, 51.7, 58.21, 62.15, 62.6, 59.61, 57.0, 50.73, 47.07, 46.97, 48.0, 47.61, 47.37, 45.9, 47.78, 46.05, 45.0, 42.58, 41.2, 42.75, 44.25, 47.56, 47.0, 44.89, 43.05, 42.4, 46.01, 46.68, 44.4, 45.0, 46.58, 45.08, 47.07, 46.18, 47.2, 51.7, 49.91, 48.72, 46.3, 47.56, 44.88, 47.47, 43.49, 42.15, 42.67, 40.86, 41.62, 42.03, 42.0, 40.3, 39.28, 36.92, 39.1, 38.9, 39.0, 38.85, 38.86, 37.65, 37.37, 36.22, 35.38, 37.5, 37.9, 37.7, 37.66, 35.54, 35.5, 35.28, 34.48, 36.4, 37.39, 36.56, 36.7, 36.65, 37.0, 37.6, 36.85, 37.94, 36.5, 35.24, 35.0, 32.32, 30.0, 30.8, 29.31, 28.6, 28.5, 27.98, 29.03, 29.0, 29.75, 30.18, 30.1, 29.11, 30.3, 30.88, 31.5, 31.73, 34.1, 34.44, 34.75, 35.35, 34.2, 34.22, 35.25, 37.69, 36.28, 35.77, 37.59, 35.98, 35.31]\n",
      "[41.5, 41.5, 43.87, 39.54, 38.9, 39.96, 41.78, 41.3, 42.98, 43.96, 47.0, 47.1, 43.94, 42.38, 41.1, 41.88, 38.86, 38.22, 38.66, 36.08, 35.34, 35.51, 35.91, 35.36, 38.34, 38.89, 39.09, 39.5, 37.4, 37.15, 39.92, 41.38, 39.8, 43.78, 44.56, 45.29, 44.4, 44.65, 43.79, 42.62, 43.05, 45.67, 45.23, 49.12, 52.5, 52.02, 56.5, 62.15, 65.0, 61.48, 56.71, 56.52, 50.73, 48.04, 48.5, 47.36, 47.36, 46.53, 48.01, 46.02, 45.27, 45.78, 41.2, 42.2, 43.87, 46.04, 46.98, 45.11, 43.25, 42.42, 45.86, 46.83, 44.88, 45.12, 47.12, 45.71, 47.7, 47.31, 47.86, 50.6, 50.41, 48.71, 47.05, 47.49, 45.19, 45.82, 44.03, 42.4, 42.79, 40.91, 40.6, 43.0, 40.69, 41.6, 37.44, 36.91, 38.68, 39.54, 39.13, 38.6, 38.98, 37.91, 37.49, 36.36, 35.17, 37.99, 38.2, 37.9, 37.74, 35.82, 35.62, 34.9, 34.93, 36.01, 37.91, 36.57, 37.12, 36.75, 37.61, 37.25, 36.99, 37.9, 36.9, 35.24, 34.84, 34.3, 30.87, 30.9, 29.65, 28.29, 28.45, 28.47, 29.32, 29.22, 29.74, 29.39, 29.71, 29.07, 30.17, 30.89, 31.56, 31.82, 35.0, 34.14, 34.76, 34.86, 34.55, 34.31, 35.7, 37.82, 36.43, 36.42, 37.85, 36.52, 35.09, 35.37]\n"
     ]
    }
   ],
   "source": [
    "# 2023-4-10\n",
    "# 新的列表，用于存储提取后的值\n",
    "open_price_pre = []  # 预测天的开盘价\n",
    "close_price_pre = []  # 预测天的收盘价\n",
    "open_price_today=[]  # 当天开盘价\n",
    "close_price_today=[]\n",
    "\n",
    "\n",
    "# 循环遍历每个索引\n",
    "for i in label_indices_pre:\n",
    "    # 提取第 i 个数据集中 'stock' 的 (0,0) 位置的值\n",
    "    open_value = round(dataset[i]['stock'].x[0, 0].item(),2)  # 提取并转换为 float\n",
    "    open_price_pre.append(open_value)  # 保存到新的列表中\n",
    "    \n",
    "    close_value = round(dataset[i]['stock'].x[0, 3].item(),2)  # 提取并转换为 float\n",
    "    close_price_pre.append(close_value)  # 保存到新的列表中\n",
    "\n",
    "open_price_today=open_price_pre    \n",
    "print(open_price_today)\n",
    "open_price_today.insert(0, open_price)\n",
    "print(open_price_today)\n",
    "\n",
    "close_price_today=close_price_pre\n",
    "close_price_today.insert(0,close_price)\n",
    "print(close_price_today)\n",
    "\n",
    "# 输出新的列表\n",
    "print(open_price_pre)\n",
    "print(close_price_pre)\n",
    "\n",
    "print(open_price_today)\n",
    "print(close_price_today)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGTExplicit(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels1, hidden_channels2, hidden_channels3, out_channels1, out_channels2, num_heads, metadata1, metadata2):\n",
    "        super().__init__()\n",
    "\n",
    "        # 定义两层 HGT 卷积\n",
    "        \n",
    "        self.conv1 = HGTConv(in_channels, hidden_channels1, metadata1, num_heads)\n",
    "        self.conv2 = HGTConv(hidden_channels1, hidden_channels2, metadata2, num_heads)\n",
    "        self.conv3 = HGTConv(hidden_channels2, hidden_channels3, metadata2, num_heads)\n",
    "        # self.conv4 = HGTConv(hidden_channels3, hidden_channels4, metadata2, num_heads)\n",
    "\n",
    "        # 用于将 connect 节点特征从 5 维转换为 hidden_channels1\n",
    "        self.connect_lin1 = torch.nn.Linear(5, hidden_channels1)\n",
    "        self.connect_lin2 = torch.nn.Linear(5, hidden_channels2)\n",
    "        self.connect_lin3 = torch.nn.Linear(5, hidden_channels3)\n",
    "        \n",
    "        self.fs_lin1= torch.nn.Linear(2, hidden_channels1)\n",
    "        # 用于将 connect 节点特征从 hidden_channels1 转换为 hidden_channels2\n",
    "        self.fs_lin2 = torch.nn.Linear(2, hidden_channels2)\n",
    "        self.fs_lin3 = torch.nn.Linear(2, hidden_channels3)\n",
    "        \n",
    "        # Dropout 层\n",
    "        self.dropout = torch.nn.Dropout(p=0.5)\n",
    "        \n",
    "        # 输出层\n",
    "        self.gru=torch.nn.GRU(hidden_channels3, out_channels1)\n",
    "        self.lstm=torch.nn.LSTM(hidden_channels3, out_channels1)\n",
    "        #  self._initialize_weights()  # 初始化权重\n",
    "        \n",
    "        self.out1 = Linear(hidden_channels3, out_channels1)\n",
    "        self.out2 = Linear(out_channels1, out_channels2)\n",
    "        # self.out3 = Linear(out_channels2, out_channels3)\n",
    "        \n",
    "        # 初始化 GRU 权重\n",
    "        # self._initialize_weights()\n",
    "        # 定义 PyG 的特征归一化变换\n",
    "        self.normalize = T.NormalizeFeatures()\n",
    "        \n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "        \n",
    "        # 对整个异构图进行归一化\n",
    "        # data = self.normalize(data)\n",
    "        # 获取 x_dict, edge_index_dict, edge_attr_dict\n",
    "        x_dict, edge_index_dict, edge_attr_dict = data.x_dict, data.edge_index_dict, data.edge_attr_dict\n",
    "\n",
    "        \n",
    "        connect_initial = x_dict['connect']\n",
    "        financing_initial = x_dict['financing']\n",
    "        selling_initial = x_dict['selling']\n",
    "\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict, edge_attr_dict)\n",
    "        x_dict = {node_type: F.leaky_relu(x) for node_type, x in x_dict.items()}\n",
    "        # 应用Dropout\n",
    "        x_dict = {node_type: self.dropout(x) for node_type, x in x_dict.items()} #神经元已经提取了特征，再对这些特征进行随机“丢弃”可以更好地防止过拟合。\n",
    "               \n",
    "        # 移除不再使用的节点\n",
    "        for key in ['connect', 'financing', 'selling']:\n",
    "            if key in x_dict:\n",
    "                del x_dict[key]\n",
    "\n",
    "        for edge_type in [('connect', 'invest', 'stock'), ('financing', 'invest', 'stock'), ('selling', 'invest', 'stock')]:\n",
    "            if edge_type in edge_index_dict:\n",
    "                del edge_index_dict[edge_type]\n",
    "            if edge_type in edge_attr_dict:\n",
    "                del edge_attr_dict[edge_type]\n",
    "        \n",
    "        # 第二层 HGT 卷积\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict, edge_attr_dict)\n",
    "        x_dict = {node_type: F.leaky_relu(x) for node_type, x in x_dict.items()}\n",
    "        x_dict = {node_type: self.dropout(x) for node_type, x in x_dict.items()} \n",
    "\n",
    "        # 第三层 HGT 卷积\n",
    "        x_dict = self.conv3(x_dict, edge_index_dict,edge_attr_dict)\n",
    "        x_dict = {node_type: F.leaky_relu(x) for node_type, x in x_dict.items()}\n",
    "        x_dict = {node_type: self.dropout(x) for node_type, x in x_dict.items()} \n",
    "        \n",
    "        \n",
    "        \n",
    "        out=F.leaky_relu(self.out1(x_dict['stock']))\n",
    "        out=self.out2(out)[::12]\n",
    "\n",
    "        return out\n",
    "    \n",
    "# 传参        \n",
    "in_channels = {\n",
    "    'stock': 15,\n",
    "    'other': 768,\n",
    "    'connect': 3,\n",
    "    'financing': 2,\n",
    "    'selling': 2\n",
    "}\n",
    "\n",
    "metadata1 = (['stock', 'other', 'connect', 'financing', 'selling'], [\n",
    "    ('stock', 'spearman', 'stock'),\n",
    "    ('connect', 'invest', 'stock'),\n",
    "    ('financing', 'invest', 'stock'),\n",
    "    ('selling', 'invest', 'stock'),\n",
    "    ('stock', 'relationship', 'stock'),\n",
    "    ('stock', 'relationship', 'other'),\n",
    "    ('other', 'relationship', 'stock'),\n",
    "    ('other', 'relationship', 'other')\n",
    "])\n",
    "\n",
    "metadata2 = (['stock', 'other',], [\n",
    "    ('stock', 'spearman', 'stock'),\n",
    "    ('stock', 'relationship', 'stock'),\n",
    "    ('stock', 'relationship', 'other'),\n",
    "    ('other', 'relationship', 'stock'),\n",
    "    ('other', 'relationship', 'other')\n",
    "])\n",
    "\n",
    "hidden_channels1 = 256\n",
    "hidden_channels2 = 32\n",
    "hidden_channels3 = 32\n",
    "out_channels1 = 32\n",
    "out_channels2 = 2\n",
    "\n",
    "num_heads = 32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HGTExplicit(in_channels, hidden_channels1, hidden_channels2, hidden_channels3, out_channels1, out_channels2, num_heads, metadata1, metadata2)\n",
    "model.load_state_dict(torch.load('/home/QFRC/ZQS/Projects/Graph/Scripts_demo/Improve/3days/Grid_saves_顺序/models/256_32_32_32/ACC_0.5548_MCC_0.2044_Precision_0.5221_Recall_0.9467_F1_0.6730_AUC_0.5702_133265.pth'))  # 加载保存的模型权重\n",
    "model.eval()  # 设置为评估模式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "total_loss = 0\n",
    "labels = []\n",
    "preds = []\n",
    "probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in (val_loader):\n",
    "        \n",
    "        y = data['stock'].y[:, 0].to(dtype=torch.long)  # (batch_size, num_stocks) -> (num_stocks, batch_size)\n",
    "        \n",
    "        output = model(data)  # 输出形状: (num_stocks, batch_size)\n",
    "        # print(output)\n",
    "        loss = criterion(output, y)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "            # 获取预测概率\n",
    "        probs_batch = torch.softmax(output, dim=1)[:, 1]  # 只取正类的概率\n",
    "        \n",
    "        # 将logits转为概率并转为二元预测\n",
    "        preds_batch = torch.argmax(output, dim=1)  # 获取类别预测\n",
    "        \n",
    "        labels.extend(y.cpu().numpy())\n",
    "        preds.extend(preds_batch.cpu().numpy())\n",
    "        probs.extend(probs_batch.cpu().numpy())\n",
    "        \n",
    "\n",
    "# 计算评价指标\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "precision = precision_score(labels, preds, zero_division=1)\n",
    "recall = recall_score(labels, preds, zero_division=1)\n",
    "f1 = f1_score(labels, preds, zero_division=1)\n",
    "mcc= matthews_corrcoef(labels, preds)\n",
    "\n",
    "# 计算AUC\n",
    "try:\n",
    "    auc = roc_auc_score(labels, probs)\n",
    "except ValueError:\n",
    "    auc = 0  # 如果计算AUC时遇到问题，例如只有一种类标签\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}, Mcc: {mcc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}, AUC: {auc:.4f}')\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds)\n",
    "print(y)\n",
    "print(len(preds))\n",
    "print(len(y))\n",
    "print(type(preds))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟投资\n",
    "# # 4-9准备投资，预测出的涨跌是4-10~11-27\n",
    "# preds：预测一共155个交易日收盘价的涨跌\n",
    "# open_price_today：155个交易日的开盘价和前一天的开盘价\n",
    "# open_price_pre：155个交易日的开盘价\n",
    "# close_price_today：155天个交易日收盘价和前一天的开盘价\n",
    "# close_price_pre：155个交易日的收盘价\n",
    "\n",
    "# 逻辑：预测下一交易日上涨，则下一交易日开盘价买入\n",
    "\n",
    "\n",
    "# 初始资金\n",
    "initial_capital = 100000  # 10 万元初始资金\n",
    "capital = initial_capital\n",
    "position = 0  # 初始没有持仓\n",
    "cash = capital\n",
    "\n",
    "# 记录每日资产\n",
    "capital_history = []\n",
    "\n",
    "# 记录买入的标志\n",
    "bought = False\n",
    "        \n",
    "\n",
    "# 回测逻辑，处理前154天\n",
    "for i in range(len(preds) - 1):  # 循环到倒数第二天，最后一天单独处理\n",
    "    if not bought and preds[i] == 1:  # 如果还未买入且预测当天上涨\n",
    "        # 预测上涨，所以以当天的开盘价买入\n",
    "        position = cash // open_price_today[i]  # 以当天的开盘价买入\n",
    "        cash -= position * open_price_today[i]  # 扣除买入股票的花费\n",
    "        print(f\"第{i}天：开盘价 {open_price_today[i]} 买入 {position} 股，剩余现金 {cash:.2f}\")\n",
    "        bought = True\n",
    "    elif bought and preds[i] == 0:  # 如果已经持仓且预测当天下跌，则当天开盘卖出\n",
    "        cash += position * open_price_today[i]  # 以当天的开盘价卖出\n",
    "        print(f\"第{i}天：以开盘价 {open_price_today[i]} 卖出 {position} 股，现金 {cash:.2f}\")\n",
    "        position = 0  # 清空持仓\n",
    "        bought = False\n",
    "        \n",
    "    # 记录每日的总资金（现金 + 持仓市值）\n",
    "    if bought:\n",
    "        total_assets = cash + position * close_price_today[i]  # 现金 + 持仓股票市值（按收盘价计算）\n",
    "    else:\n",
    "        total_assets = cash  # 只有现金，没有持仓\n",
    "\n",
    "    capital_history.append(round(total_assets,2))  # 记录每日的总资产\n",
    "\n",
    "        \n",
    "# 调试输出，检查最后一天前是否持有股票\n",
    "print(f\"最后一个交易日前，持仓股数: {position}, 预测结果: {preds[-1]}\")\n",
    "\n",
    "# 特殊处理最后一个交易日（第155天）\n",
    "if preds[-1] == 1:  # 如果预测最后一天（第155天）上涨\n",
    "    if position > 0:\n",
    "        cash += position * close_price_today[-1]  # 以最后一天的收盘价卖出\n",
    "        print(f\"最后一天：收盘价 {close_price_today[-1]} 卖出 {position} 股，现金 {cash:.2f}\")\n",
    "        position = 0  # 清空持仓\n",
    "    else:\n",
    "        print(\"最后一天预测上涨，但没有持仓，无法卖出\")\n",
    "elif preds[-1] == 0:  # 如果预测最后一天（第155天）下跌\n",
    "    if position > 0:\n",
    "        cash += position * open_price_today[-1]  # 以最后一天的开盘价卖出\n",
    "        print(f\"最后一天：开盘价 {open_price_today[-1]} 卖出 {position} 股，现金 {cash:.2f}\")\n",
    "        position = 0  # 清空持仓\n",
    "    else:\n",
    "        print(\"最后一天预测下跌，但没有持仓，无法卖出\")\n",
    "else:\n",
    "    print(\"预测结果没有定义\")\n",
    "    \n",
    "# 最后一天的总资金记录\n",
    "capital_history.append(round(cash,2))  # 无论是否有持仓，最后一天全部资金都变为现金    \n",
    "ration_capital= [(capital_history[i] - initial_capital) / initial_capital * 100 for i in range(1, len(capital_history))]\n",
    "    \n",
    "print(capital_history)\n",
    "print(ration_capital)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 买入并持有策略逻辑\n",
    "buy_and_hold_history = []\n",
    "\n",
    "# 第一天开盘价买入所有股票\n",
    "buy_and_hold_position = initial_capital // open_price_today[0]\n",
    "buy_and_hold_cash = initial_capital - buy_and_hold_position * open_price_today[0]\n",
    "\n",
    "# 计算每一天的总资金（持有股票市值 + 现金）\n",
    "for i in range(len(close_price_today)):\n",
    "    buy_and_hold_assets = buy_and_hold_cash + buy_and_hold_position * close_price_today[i]  # 现金 + 股票市值\n",
    "    buy_and_hold_history.append(buy_and_hold_assets)\n",
    "\n",
    "# 最后一天全部持仓卖出\n",
    "buy_and_hold_cash += buy_and_hold_position * close_price_today[-1]\n",
    "buy_and_hold_history.append(buy_and_hold_cash)\n",
    "\n",
    "ration_buy_and_hold= [(buy_and_hold_history[i] - initial_capital) / initial_capital * 100 for i in range(1, len(capital_history))]\n",
    "\n",
    "\n",
    "print(buy_and_hold_history)\n",
    "print(ration_buy_and_hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制资金变化折线图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(capital_history, label=\"MT\",  linestyle='-', color='#B19CD9')\n",
    "plt.plot(buy_and_hold_history, label=\"B&H\", linestyle='-', color='#FFD580')\n",
    "plt.title(\"Accumulate Capital\", fontsize=16)\n",
    "plt.xlabel(\"Trading day\", fontsize=12)\n",
    "plt.ylabel(\"RMB (¥)\", fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zqs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
