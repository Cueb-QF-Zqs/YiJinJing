# ✨ 易金经——LLM驱动下融合数据底座和智能投资的金融服务解决方案
### Yi Jin Jing: An LLM-driven financial service solution integrating data foundation and intelligent investment

## 🧠 项目背景与设计理念

“易金经”的命名灵感源于中国古籍《易筋经》。

《易筋经》强调通过调理筋脉、贯通经络，重塑身体的内在运行结构。本项目以此为喻，将金融文本、市场数据、知识图谱与智能模型视作“金融信息的经络系统”，通过 LLM、知识底座与智能投资模型的深度融合，重构金融知识体系的采集、组织与传导方式，使金融信息在系统内实现更加顺畅、高效、智能的流动与转化。

易金经基于生成式人工智能、知识图谱和图机器学习等技术体系，打造LLM驱动下融合知识底座和智能投资的金融服务解决方案。方案通过设计FinEX金融知识抽取智能体，实现对新闻公告、资讯舆情的金融文本分析、金融事件抽取和结构化金融知识生成。基于时序多模态知识图谱，完成多模态知识底座的自动化构建；并自研MEHGT多模态异构图神经网络预测模型，实现交易信号生成与智能资产配置。最终形成“知识抽取——数据底座——智能决策”的金融服务闭环


---

## 📁 项目结构

本仓库采用按功能模块分层的目录结构，便于独立开发与联合调试。

    易金经/
    ├── MEHGT边增强的异构图神经网络/
    │   ├── HGTConv.py
    │   ├── han_conv_edge_attr3.py
    │   ├── readme.md
    │   ├── 回测demo1.ipynb
    │   ├── 浪潮信息_Grid_顺序.py
    │   └── figs/                     # 存放 MEHGT 相关图示与回测可视化结果
    │
    ├── 微调FinEX/
    │   ├── Merge.sh                  # LoRA 权重合并脚本
    │   ├── Quant.sh                  # FinEX 量化与推理脚本
    │   ├── SFT_TF-14B.sh             # 监督微调（SFT）主脚本
    │   ├── Web_demo.sh               # Web Demo 启动脚本
    │   └── readme.md
    │
    ├── 时序多模态知识图谱/
    │   ├── HeteroG_eventall2.0.ipynb # 事件级异构图构建与可视化
    │   ├── readme.md
    │   ├── toexcel_gpu1.ipynb        # 图谱导出与特征入仓
    │   └── 比亚迪（21-24）_deldata3.xlsx # 行业/个股示例数据
    │
    ├── LICENSE
    ├── README.md
    └── requirements.txt              # Python 依赖环境

---

## 🔧 运行环境与依赖说明

本项目主要基于 Python 生态构建，核心依赖包括但不限于：

- 深度学习与大模型框架：`PyTorch`、`transformers`、`peft`、`accelerate`
- 图神经网络：`PyTorch Geometric` 及其相关扩展
- 数据处理与可视化：`pandas`、`numpy`、`matplotlib`、`seaborn`
- Web 与服务部署：`gradio` 或 `fastapi`（视实际接入方式而定）

建议通过 `conda` 或 `venv` 创建独立环境，并使用仓库根目录下的 `requirements.txt` 一键安装依赖：

    conda create -n yjj python=3.10
    conda activate yjj
    pip install -r requirements.txt

---

# 🧩 模块一：FinEX（小金豆）金融知识抽取智能体

## 📖 1.1 模块简介

FinEX（小金豆）是面向金融领域设计的知识抽取与结构化表示智能体。其基于通义千问大模型进行Lora监督微调微调，通过高质量金融标注语料与任务定制式指令，从财经新闻、公告、研报等非结构化文本中自动识别关键信息（如金融事件、金融实体、金融动作等），并生成可直接入库与建图的结构化元组（三元组/二元组）。


## 🧱 1.2 技术细节与实现路线（含示意图）

- 微调框架：FinEX 的训练流程参考并基于 LLaMA Factory 框架进行二次开发，微调脚本与参数配置可见目录 `微调FinEX/` 中的 `.sh` 文件，原始框架参考：
  
  - LLaMA Factory: <https://github.com/hiyouga/LLaMA-Factory>

- 模型基座与参数配置：
  
  - 使用金融语料增强的中英文大模型作为基座（Tongyi-Finance 14B）。
  - 采用 LoRA / QLoRA 等参数高效微调技术，侧重对输出层与部分中间层的适配。
  - 完整的模型权重与参数配置详见：
    
    - ModelScope: <https://www.modelscope.cn/models/Madness977/FinEX>

- 任务建模与指令设计：
  
  - 将金融事件抽取与结构化表示建模为指令式生成任务，通过 prompt 约束输出格式。
  - 支持多粒度输出：事件级三元组、指标级二元组、以及多事件联合解析。

- 训练脚本示例（参考）：

    - `SFT_TF-14B.sh`：监督微调主流程（数据加载、策略设定、分布式训练）。
    - `Merge.sh`：微调权重与底模合并，形成独立推理模型。
    - `Quant.sh`：模型量化（如 4bit/8bit）与部署加速。
    - `Web_demo.sh`：启动 FinEX 在线演示服务。

- 架构示意图（请将下述路径替换为实际图片文件名）：

    ![FinEX 模型总体架构示意图](figs/FinEX.png)

- 网页部署推理示例（支持中英文双语）：
    ![FinEX 网页部署推理示例](figs/中文知识抽取示例.png)

---

## 📊 1.3 效果评估与可视化

- 评估任务：金融事件抽取与结构化元组生成。
- 核心指标：
  
  - 文本级：Precision / Recall / F1、句级解析成功率；
  - 结构化级：三元组召回率、实体对齐准确率、事件覆盖率等。

- 典型结论示例：
  
  - 在金融公告与新闻测试集上，FinEX 在 Precision / Recall / F1 三个指标上均优于通用开源模型及未微调基线模型；
  - 对复杂长文本的多事件解析能力显著提升，能够稳定输出符合预期 schema 的结构化元组。
- 对比结果  

    ![FinEX 事件抽取与结构化表示效果示例](figs/NLP结果.png)

---

# 🌐 模块二：时序多模态知识图谱

## 📖 2.1 模块简介

时序多模态知识图谱模块以 FinEX 输出的结构化元组为基础，结合行情数据、财务指标、行业划分等多源信息，将离散的金融事件、主体实体与市场信号统一映射到时序异构图结构中，为下游预测模型提供“可计算、可推理、可追溯”的数据底座。

该模块重点关注：

- 多模态（文本、数值、图结构）融合；
- 时序维度上的滚动更新与版本管理。

## 🧱 2.2 技术细节与实现流程

- 图谱构建流程：
  
  1. 实体对齐：对公司名称、证券代码、行业标签等进行标准化处理；

  3. 时序切片：按交易日/公告日构建时序图快照，或采用滑动窗口形成 block 图；
  4. 图存储与导出：通过 `HeteroG_eventall2.0.ipynb` 和 `toexcel_gpu1.ipynb` 完成异构图结构构建、可视化与特征导出。

- 相关 Notebook：
  
  - `HeteroG_eventall2.0.ipynb`：时序多模态异构图构建与可视化；
  - `toexcel_gpu1.ipynb`：将图谱特征导出到表格 / 特征仓，用于后续 GNN 或传统模型；
  - `比亚迪（21-24）_deldata3.xlsx`：示例股票/时间区间的数据集。


## 📊 2.3 示例展示


- 基于neo4j的可视化示例：

    ![时序多模态知识图谱可视化与应用示例](figs/neo4j.png)

---

# 📈 模块三：MEHGT 多模态异构图神经网络

## 📖 3.1 模块简介

MEHGT（Multimodal Edge-enhanced Heterogeneous Graph Transformer）边增强的多模态异构图神经网络模型。其核心思想是：

- 使用异构图 Transformer 结构统一处理不同类型的节点与边；
- 在边级引入多模态信息（文本事件、数值指标、情感信号等），以增强消息传递与注意力计算；
- 在时序维度上结合窗口滚动与回测机制，对股票趋势、风险事件等进行预测与评估。


## 🧱 3.2 技术细节与模型实现

- 模型结构概览：
  
  - 输入：来自时序多模态知识图谱的异构图序列（节点包含公司、事件、行业等，多类型边携带数值与文本嵌入特征）；
  - 图表征层：多层 MEHGT / HGTConv / HANConv 模块，对不同节点类型学习类型特异的投影，并在边上融合事件、情感与量价信息；
  - 时序建模：可结合 Transformer、TCN 或 BiLSTM 对多日图嵌入序列进行时序编码；
  - 输出层：对目标股票/节点输出涨跌方向或风险标签，同时输出注意力权重用于可解释性分析。

## 📊 3.3 预测与回测效果评估

- 预测任务：
  
  - 个股/行业的短期趋势预测（涨跌分类 / 回报回归）；
  - 风险事件触发前后的异常波动检测。

- 评价指标：
  
  - 分类层面：Accuracy、Precision、Recall、F1、AUC、MCC 等；
  - 投资回测层面：累计收益率（CRR）、最大回撤（MDD）、夏普比率（Sharpe）、胜率与换手率等。

- 回测与可视化：
  
  - 在 `回测demo1.ipynb` 中实现从预测信号到交易指令的映射逻辑，并绘制净值曲线、回撤曲线及指标对比；
  - 对比基准策略（如买入持有、简单因子策略）与 MEHGT 策略的收益与风险特征。

- 实验结果示例：

    ![MEHGT 回测结果与指标对比示意图](figs/对比结果.png)
    ![MEHGT 回测结果与指标对比示意图](figs/回测.png)


---


# ⚠️ 注意事项

1. **数据合规与隐私保护**  
   - 请确保使用的数据来源合法、合规，尤其是涉及上市公司公告与金融机构内部数据时需遵守相应监管与合约条款。  
   - 不要在仓库中直接上传包含敏感信息的原始数据，可通过脱敏与聚合方式处理后再用于训练与展示。

2. **资源与性能要求**  
   - FinEX 微调涉及大规模 Transformer，建议使用 A100 / H100 等数据中心级 GPU，并根据显存适当调整 batch size、序列长度与 LoRA 配置。  
   - MEHGT 训练对显存与带宽要求较高，建议提前规划图采样策略与 batch 组织方式。

3. **版本兼容性**  
   - 不同 PyTorch / CUDA / transformers 版本组合可能导致行为差异，建议以 `requirements.txt` 中的版本为准。  
   - 如在多机多卡集群上运行，请注意 NCCL、accelerate/deepspeed 等组件的配置一致性。

4. **随机种子与复现实验**  
   - 为保证实验可复现，建议统一设置随机种子，并在训练日志中记录关键超参数与数据切分方式（训练集/验证集/测试集）。

---

# 🔮 未来展望与拓展方向

1. **金融服务平台不断适配**  
未来将推动解决方案与银行、财富管理、保险等核心金融平台深度融合，形成可复用的智能金融能力层。依托知识抽取、数据整合与投资分析能力，帮助用户在既有平台中获得更可信的市场解读、更精准的风险提示和更契合需求的资产配置建议。


2. **多金融场景不断拓展**  
依托 MEHGT-LKG 边增强异构图神经网络模型，团队将扩展至更多金融衍生品和细分业务场景，如智能风控、基于用户画像的个性化投资等，使系统逐步具备跨业务、跨机构的通用化扩展能力，支撑行业从“经验驱动”迈向“智能驱动”。


3. **国产金融科技自主可控**  
团队与北京昇腾智算中心深度合作，依托国产昇腾 AI 智算集群、MindSpore 框架与 RAG 检索增强，面向金融场景构建高性能模型训练与推理体系，并重点探索 CANN、异构算子与图神经网络等关键技术的适配与创新，实现算法、算力与生态的自主可控，推动本土金融科技高质量发展。

---

# 📚 附录：相关链接与引用建议

- LLaMA Factory（FinEX 微调框架参考）：  
  <https://github.com/hiyouga/LLaMA-Factory>

- FinEX 模型卡与权重：  
  <https://www.modelscope.cn/models/Madness977/FinEX>

